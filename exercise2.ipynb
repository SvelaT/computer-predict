{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f10e466-b7b8-4e2a-8bc5-7b3ccf4fd0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os as os\n",
    "# Algorithms\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a31c1-8ca4-4e39-a021-1df02a57c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"archive (2)/Laptops_data.xlsx\")\n",
    "df2 = pd.read_excel(\"archive (2)/Laptops_data.xlsx\")\n",
    "df3 = pd.read_excel(\"archive (2)/Laptops_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4c8879-1ba6-4a41-8088-29aa47ccbf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3706c7f8-f5b0-4905-9a96-85dd41a93b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select Target and Features \n",
    "\n",
    "X = dataset.data\n",
    "y = dataset.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# It's often good practice to scale the features such that they have mean=0 and variance=1\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af45af9-fec2-4032-93d6-c40d604e16b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of different algorithms\n",
    "regressors = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree Regressor': DecisionTreeRegressor(),\n",
    "    'Random Forest Regressor': RandomForestRegressor(),\n",
    "    'Gradient Boosting Regressor': GradientBoostingRegressor(),\n",
    "    'XGBoost Regressor': xgb.XGBRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d3c49c-3419-41e5-9d5b-11f44d8df795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the results\n",
    "results_list = []\n",
    "\n",
    "metric_func = mean_squared_error\n",
    "metric_name = 'Mean Squared Error'\n",
    "# Train and evaluate each model\n",
    "for model_name, model_instance in regressors.items():\n",
    "    model_instance.fit(X_train, y_train)\n",
    "    y_predicted = model_instance.predict(X_test)\n",
    "    # Compute metrics\n",
    "    mse = mean_squared_error(y_test, y_predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_predicted)\n",
    "    mape = mean_absolute_percentage_error(y_test, y_predicted)\n",
    "    r2 = r2_score(y_test, y_predicted)\n",
    "    \n",
    "    # Append results\n",
    "    results_list.append({\n",
    "        'Model': model_name, \n",
    "        'Mean Squared Error': mse,\n",
    "        'Root Mean Squared Error': rmse,\n",
    "        'Mean Absolute Error': mae,\n",
    "        'Mean Absolute Percentage Error': mape,\n",
    "        'R^2 Score': r2\n",
    "    })\n",
    "    # Optionally, print detailed classification report for each model\n",
    "    # print(f\"Classification Report for {model_name}:\\n{classification_report(y_test, y_pred)}\\n\")\n",
    "\n",
    "# Display the performance of all models in a sorted order\n",
    "results = pd.DataFrame(results_list)\n",
    "results = results.sort_values(by='R^2 Score', ascending=True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9330f000-00e8-4861-a8e9-b0d7014e267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of the results\n",
    "plt.figure(figsize=(12, 6))\n",
    "splot = plt.bar(results['Model'], results['Mean Absolute Percentage Error'], color='skyblue')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('MAPE')\n",
    "plt.title('Comparison of Model Performance')\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.ylim([0.0, 1.0])  # Assuming accuracy as the metric, limit is set to 1.0\n",
    "\n",
    "# Adding the text labels inside the bars\n",
    "for bar in splot:\n",
    "    plt.gca().text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 0.1, f\"{bar.get_height():.2%}\", \n",
    "                 ha='center', color='black', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb08dd3d-9a2d-41d9-adca-8c210a2cf08b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
